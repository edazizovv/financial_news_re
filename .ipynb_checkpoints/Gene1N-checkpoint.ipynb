{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.util import Conductor\n",
    "from codes.neuro import Gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.051394</td>\n",
       "      <td>0.553913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.023348</td>\n",
       "      <td>0.119974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.356888</td>\n",
       "      <td>1.092940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.840031</td>\n",
       "      <td>0.759874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.341335</td>\n",
       "      <td>-0.512597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>9994.976045</td>\n",
       "      <td>1.344389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>9997.210007</td>\n",
       "      <td>-0.159755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>9998.253809</td>\n",
       "      <td>1.530279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>9999.366796</td>\n",
       "      <td>0.313846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>9998.849901</td>\n",
       "      <td>-0.724381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         A            B         C\n",
       "0        0    -0.051394  0.553913\n",
       "1        1     2.023348  0.119974\n",
       "2        2     2.356888  1.092940\n",
       "3        3     2.840031  0.759874\n",
       "4        4     4.341335 -0.512597\n",
       "...    ...          ...       ...\n",
       "9995  9995  9994.976045  1.344389\n",
       "9996  9996  9997.210007 -0.159755\n",
       "9997  9997  9998.253809  1.530279\n",
       "9998  9998  9999.366796  0.313846\n",
       "9999  9999  9998.849901 -0.724381\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10_000\n",
    "data_raw = pandas.DataFrame(data={'A': numpy.array(numpy.arange(N)), \n",
    "                              'B': numpy.array(numpy.arange(N)) + numpy.random.normal(size=(N,)), \n",
    "                              'C': numpy.random.normal(size=(N,))})\n",
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'A'\n",
    "quantitative = ['C']\n",
    "qualitative = ['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 1: BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.051394</td>\n",
       "      <td>0.553913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.023348</td>\n",
       "      <td>0.119974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.356888</td>\n",
       "      <td>1.092940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.840031</td>\n",
       "      <td>0.759874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.341335</td>\n",
       "      <td>-0.512597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995.0</td>\n",
       "      <td>9994.976045</td>\n",
       "      <td>1.344389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996.0</td>\n",
       "      <td>9997.210007</td>\n",
       "      <td>-0.159755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997.0</td>\n",
       "      <td>9998.253809</td>\n",
       "      <td>1.530279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998.0</td>\n",
       "      <td>9999.366796</td>\n",
       "      <td>0.313846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999.0</td>\n",
       "      <td>9998.849901</td>\n",
       "      <td>-0.724381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A            B         C\n",
       "0        0.0    -0.051394  0.553913\n",
       "1        1.0     2.023348  0.119974\n",
       "2        2.0     2.356888  1.092940\n",
       "3        3.0     2.840031  0.759874\n",
       "4        4.0     4.341335 -0.512597\n",
       "...      ...          ...       ...\n",
       "9995  9995.0  9994.976045  1.344389\n",
       "9996  9996.0  9997.210007 -0.159755\n",
       "9997  9997.0  9998.253809  1.530279\n",
       "9998  9998.0  9999.366796  0.313846\n",
       "9999  9999.0  9998.849901 -0.724381\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decise\n",
    "\n",
    "data_set = data_raw.copy()\n",
    "\n",
    "for category in qualitative:\n",
    "    data_set[category] = data_set[category].astype('category')\n",
    "for numeric in quantitative:\n",
    "    data_set[numeric] = data_set[numeric].astype('float64')\n",
    "\n",
    "data_set[target] = data_set[target].astype('float64')\n",
    "\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct added\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "data = Conductor(data_frame=data_set, target=[target])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<codes.util.DataRoles at 0x2598ba825b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10000, 50)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.categorical_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoote-func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-params\n",
    "\n",
    "layers = [nn.Linear, nn.Linear]\n",
    "layers_dimensions = [100, 2]\n",
    "activators = [nn.Sigmoid, nn.Sigmoid]\n",
    "preprocessor=None\n",
    "# preprocessor=nn.BatchNorm1d\n",
    "embeddingdrop=0.0\n",
    "# postlayer=nn.Linear\n",
    "postlayer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(10000, 50)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.0, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=51, out_features=100, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\venv\\financial_news_re\\lib\\site-packages\\torch\\nn\\modules\\loss.py:432: UserWarning: Using a target size (torch.Size([6400])) that is different to the input size (torch.Size([6400, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (6400) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b51337f2cffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimiser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Sygm\\RAMP\\IP-02\\OSTRTA\\financial_news_re\\codes\\neuro.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, optimiser, loss_function, epochs)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                     \u001b[0msingle_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumerical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\venv\\financial_news_re\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\venv\\financial_news_re\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\venv\\financial_news_re\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2540\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mean'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2541\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2542\u001b[1;33m         \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2543\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2544\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\venv\\financial_news_re\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (6400) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# go model\n",
    "\n",
    "model = Gene(data=data, layers=layers, layers_dimensions=layers_dimensions, activators=activators, preprocessor=preprocessor,\n",
    "             embeddingdrop=embeddingdrop, postlayer=postlayer)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define Optimisation\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "epochs = 300\n",
    "model.fit(optimiser, loss_function, epochs)\n",
    "\n",
    "model.fit_plot()\n",
    "\n",
    "model.summary(loss_function=loss_function, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='train', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='validation', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='test', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat_p = model(data.data.train.categorical, data.data.train.numerical)\n",
    "Y_test_hat_p = model(data.data.test.categorical, data.data.test.numerical)\n",
    "\n",
    "Y_train_hat = numpy.argmax(Y_train_hat_p.detach().numpy(), axis=1)\n",
    "Y_test_hat = numpy.argmax(Y_test_hat_p.detach().numpy(), axis=1)\n",
    "\n",
    "Y_train = data.data.train.output.detach().numpy()\n",
    "Y_test = data.data.test.output.detach().numpy()\n",
    "\n",
    "train_roc_auc = roc_auc_score(Y_train, Y_train_hat)\n",
    "test_roc_auc = roc_auc_score(Y_test, Y_test_hat)\n",
    "\n",
    "train_gini = 2 * train_roc_auc - 1\n",
    "test_gini = 2 * test_roc_auc - 1\n",
    "\n",
    "print(\"Train ROC-AUC:\\t {0:.4f}\".format(train_roc_auc))\n",
    "print(\"Test ROC-AUC:\\t {0:.4f}\".format(test_roc_auc))\n",
    "\n",
    "print(\"Train Gini:\\t {0:.4f}\".format(train_gini))\n",
    "print(\"Test Gini:\\t {0:.4f}\".format(test_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 2: changed N of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decise\n",
    "\n",
    "data_set = data_raw.copy()\n",
    "\n",
    "categorical_columns = categorical_columns + wut\n",
    "numerical_columns = numerical_columns + qq\n",
    "drops = drops + megafon\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data_set[category] = data_set[category].astype('category')\n",
    "for numeric in numerical_columns:\n",
    "    data_set[numeric] = data_set[numeric].astype('float64')\n",
    "\n",
    "data_set[outputs[0]] = data_set[outputs[0]].astype('category')\n",
    "data_set = data_set.drop(columns=drops)\n",
    "\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct added\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "data = Conductor(data_frame=data_set, target=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoote-func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-params\n",
    "\n",
    "layers = [nn.Linear, nn.Linear]\n",
    "layers_dimensions = [200, 2]\n",
    "activators = [nn.Sigmoid, nn.Sigmoid]\n",
    "preprocessor=None\n",
    "# preprocessor=nn.BatchNorm1d\n",
    "embeddingdrop=0.0\n",
    "# postlayer=nn.Linear\n",
    "postlayer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go model\n",
    "\n",
    "model = Gene(data=data, layers=layers, layers_dimensions=layers_dimensions, activators=activators, preprocessor=preprocessor,\n",
    "             embeddingdrop=embeddingdrop, postlayer=postlayer)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define Optimisation\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "epochs = 300\n",
    "model.fit(optimiser, loss_function, epochs)\n",
    "\n",
    "model.fit_plot()\n",
    "\n",
    "model.summary(loss_function=loss_function, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary(on='train', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='validation', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary(on='test', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat_p = model(data.data.train.categorical, data.data.train.numerical)\n",
    "Y_test_hat_p = model(data.data.test.categorical, data.data.test.numerical)\n",
    "\n",
    "Y_train_hat = numpy.argmax(Y_train_hat_p.detach().numpy(), axis=1)\n",
    "Y_test_hat = numpy.argmax(Y_test_hat_p.detach().numpy(), axis=1)\n",
    "\n",
    "Y_train = data.data.train.output.detach().numpy()\n",
    "Y_test = data.data.test.output.detach().numpy()\n",
    "\n",
    "train_roc_auc = roc_auc_score(Y_train, Y_train_hat)\n",
    "test_roc_auc = roc_auc_score(Y_test, Y_test_hat)\n",
    "\n",
    "train_gini = 2 * train_roc_auc - 1\n",
    "test_gini = 2 * test_roc_auc - 1\n",
    "\n",
    "print(\"Train ROC-AUC:\\t {0:.4f}\".format(train_roc_auc))\n",
    "print(\"Test ROC-AUC:\\t {0:.4f}\".format(test_roc_auc))\n",
    "\n",
    "print(\"Train Gini:\\t {0:.4f}\".format(train_gini))\n",
    "print(\"Test Gini:\\t {0:.4f}\".format(test_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 3: with additional fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who is who\n",
    "\n",
    "drops = ['al_ContractNumber', 'res_npl_90', 'res_payout_principal_inTime', 'res_payout_principal_delay15', \n",
    "         'res_payout_principal_delay30', 'res_payout_principal_delay45', 'res_payout_principal_delay60',\n",
    "         'res_payout_principal_delay90', 'res_payout_tot_inTime', 'res_payout_tot_delay15', 'res_payout_tot_delay30',\n",
    "         'res_payout_tot_delay45', 'res_payout_principal_delay60', 'res_payout_principal_delay90', 'res_payout_tot_inTime',\n",
    "         'res_payout_tot_delay15', 'res_payout_tot_delay30', 'res_payout_tot_delay45', 'res_payout_tot_delay60',\n",
    "         'res_payout_tot_delay90', 'fl_cnt', 'fl_cnt_during_3M', 'fl_cnt_during_12M', 'fl_requests_cnt_12M', 'is_test']\n",
    "\n",
    "categorical_columns = ['al_issue_M', 'psp_issue_rgn', 'sex', 'is_client_local', 'has_snils', 'zaim_cards', 'age', \n",
    "                       'responsecode', 'was_garant', 'is_pboul', 'has_foreign_currency_credits', 'cred_line_state',\n",
    "                       'potreb_tot', 'pdl_tot', 'avg_pdl_full_cost']\n",
    "\n",
    "numerical_columns = ['al_amount', 'avg_pdl_amount']\n",
    "\n",
    "wut = ['has_resold_credits', 'avg_payout_period_pdl']\n",
    "\n",
    "megafon = ['al_LIFETIME_BIN', 'al_BLOCK_DUR', 'al_CIRCLE', 'al_ALL_CLC', 'al_PAY_MAX', 'al_SCORE2']\n",
    "\n",
    "outputs = ['res_npl_15']\n",
    "\n",
    "qq = ['court_counts', 'official_count', 'potreb_closed_tot', 'potreb_active_tot', 'potreb_other_states_tot',\n",
    "      'pdl_closed_tot', 'pdl_active_tot', 'pdl_other_states_tot', 'pdl_own_share', 'pdl_delay5_cnt', 'pdl_delay30_cnt',\n",
    "      'pdl_delay60_cnt', 'pdl_delay90_cnt', 'pdl_delay_more_cnt', 'pdl_prolong_cnt',\n",
    "      'pdl_delay5_avg', 'pdl_delay30_avg', 'pdl_delay60_avg', 'pdl_delay90_avg', 'pdl_delay_more_avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decise\n",
    "\n",
    "data_set = data_raw.copy()\n",
    "\n",
    "categorical_columns = categorical_columns + wut\n",
    "numerical_columns = numerical_columns + qq\n",
    "drops = drops + megafon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n",
    "added_categorical = []\n",
    "added_numerical = ['court_rate', 'potreb_closed_rate', 'potreb_active_rate', 'potreb_other_states_rate',\n",
    "                   'pdl_closed_rate', 'pdl_active_rate', \n",
    "                   'pdl_delay5_cnt_rate', 'pdl_delay30_cnt_rate', 'pdl_delay60_cnt_rate', 'pdl_delay90_cnt_rate', 'pdl_delay_more_cnt_rate',\n",
    "                   'pdl_delay5_avg_rate', 'pdl_delay30_avg_rate', 'pdl_delay60_avg_rate', 'pdl_delay90_avg_rate', 'pdl_delay_more_avg_rate',\n",
    "                   'pdl_delay5_cnt_to_avg', 'pdl_delay30_cnt_to_avg', 'pdl_delay60_cnt_to_avg', 'pdl_delay90_cnt_to_avg']\n",
    "\n",
    "added_drop = ['potreb_sum', 'pdl_sum', 'pdl_cnt_sum', 'pdl_avg_sum']\n",
    "\n",
    "data_set['court_rate'] = data_set['official_count'] / data_set['court_counts']\n",
    "data_set['potreb_sum'] = data_set['potreb_closed_tot'] + data_set['potreb_active_tot'] + data_set['potreb_other_states_tot']\n",
    "data_set['potreb_closed_rate'] = data_set['potreb_closed_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_active_rate'] = data_set['potreb_active_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_other_states_rate'] = data_set['potreb_other_states_tot'] / data_set['potreb_sum']\n",
    "data_set['pdl_sum'] = data_set['pdl_closed_tot'] + data_set['pdl_active_tot']\n",
    "data_set['pdl_closed_rate'] = data_set['pdl_closed_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_active_rate'] = data_set['pdl_active_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_cnt_sum'] = data_set['pdl_delay5_cnt'] + data_set['pdl_delay30_cnt'] + data_set['pdl_delay60_cnt'] + data_set['pdl_delay90_cnt'] + data_set['pdl_delay_more_cnt'] # + data_set['pdl_prolong_cnt']\n",
    "data_set['pdl_delay5_cnt_rate'] = data_set['pdl_delay5_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay30_cnt_rate'] = data_set['pdl_delay30_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay60_cnt_rate'] = data_set['pdl_delay60_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay90_cnt_rate'] = data_set['pdl_delay90_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay_more_cnt_rate'] = data_set['pdl_delay_more_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_prolong_cnt_rate'] = data_set['pdl_prolong_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_avg_sum'] = data_set['pdl_delay5_avg'] + data_set['pdl_delay30_avg'] + data_set['pdl_delay60_avg'] + data_set['pdl_delay90_avg'] + data_set['pdl_delay_more_avg']\n",
    "data_set['pdl_delay5_avg_rate'] = data_set['pdl_delay5_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay30_avg_rate'] = data_set['pdl_delay30_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay60_avg_rate'] = data_set['pdl_delay60_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay90_avg_rate'] = data_set['pdl_delay90_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay_more_avg_rate'] = data_set['pdl_delay_more_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay5_cnt_to_avg'] = data_set['pdl_delay5_cnt'] / data_set['pdl_delay5_avg']\n",
    "data_set['pdl_delay30_cnt_to_avg'] = data_set['pdl_delay30_cnt'] / data_set['pdl_delay30_avg']\n",
    "data_set['pdl_delay60_cnt_to_avg'] = data_set['pdl_delay60_cnt'] / data_set['pdl_delay60_avg']\n",
    "data_set['pdl_delay90_cnt_to_avg'] = data_set['pdl_delay90_cnt'] / data_set['pdl_delay90_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct added\n",
    "\n",
    "categorical_columns = categorical_columns + added_categorical\n",
    "numerical_columns = numerical_columns + added_numerical\n",
    "drops = drops + added_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n",
    "data_set = data_set.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
    "data_set = data_set.fillna(value=0)\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data_set[category] = data_set[category].astype('category')\n",
    "for numeric in numerical_columns:\n",
    "    data_set[numeric] = data_set[numeric].astype('float64')\n",
    "\n",
    "data_set[outputs[0]] = data_set[outputs[0]].astype('category')\n",
    "data_set = data_set.drop(columns=drops)\n",
    "\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "data = Conductor(data_frame=data_set, target=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoote-func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-params\n",
    "\n",
    "layers = [nn.Linear, nn.Linear]\n",
    "layers_dimensions = [100, 2]\n",
    "activators = [nn.Sigmoid, nn.Sigmoid]\n",
    "preprocessor=None\n",
    "# preprocessor=nn.BatchNorm1d\n",
    "embeddingdrop=0.0\n",
    "# postlayer=nn.Linear\n",
    "postlayer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go model\n",
    "\n",
    "model = Gene(data=data, layers=layers, layers_dimensions=layers_dimensions, activators=activators, preprocessor=preprocessor,\n",
    "             embeddingdrop=embeddingdrop, postlayer=postlayer)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define Optimisation\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "epochs = 300\n",
    "model.fit(optimiser, loss_function, epochs)\n",
    "\n",
    "model.fit_plot()\n",
    "\n",
    "model.summary(loss_function=loss_function, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary(on='train', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='validation', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary(on='test', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat_p = model(data.data.train.categorical, data.data.train.numerical)\n",
    "Y_test_hat_p = model(data.data.test.categorical, data.data.test.numerical)\n",
    "\n",
    "Y_train_hat = numpy.argmax(Y_train_hat_p.detach().numpy(), axis=1)\n",
    "Y_test_hat = numpy.argmax(Y_test_hat_p.detach().numpy(), axis=1)\n",
    "\n",
    "Y_train = data.data.train.output.detach().numpy()\n",
    "Y_test = data.data.test.output.detach().numpy()\n",
    "\n",
    "train_roc_auc = roc_auc_score(Y_train, Y_train_hat)\n",
    "test_roc_auc = roc_auc_score(Y_test, Y_test_hat)\n",
    "\n",
    "train_gini = 2 * train_roc_auc - 1\n",
    "test_gini = 2 * test_roc_auc - 1\n",
    "\n",
    "print(\"Train ROC-AUC:\\t {0:.4f}\".format(train_roc_auc))\n",
    "print(\"Test ROC-AUC:\\t {0:.4f}\".format(test_roc_auc))\n",
    "\n",
    "print(\"Train Gini:\\t {0:.4f}\".format(train_gini))\n",
    "print(\"Test Gini:\\t {0:.4f}\".format(test_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 4: with additional fields + changed N of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who is who\n",
    "\n",
    "drops = ['al_ContractNumber', 'res_npl_90', 'res_payout_principal_inTime', 'res_payout_principal_delay15', \n",
    "         'res_payout_principal_delay30', 'res_payout_principal_delay45', 'res_payout_principal_delay60',\n",
    "         'res_payout_principal_delay90', 'res_payout_tot_inTime', 'res_payout_tot_delay15', 'res_payout_tot_delay30',\n",
    "         'res_payout_tot_delay45', 'res_payout_principal_delay60', 'res_payout_principal_delay90', 'res_payout_tot_inTime',\n",
    "         'res_payout_tot_delay15', 'res_payout_tot_delay30', 'res_payout_tot_delay45', 'res_payout_tot_delay60',\n",
    "         'res_payout_tot_delay90', 'fl_cnt', 'fl_cnt_during_3M', 'fl_cnt_during_12M', 'fl_requests_cnt_12M', 'is_test']\n",
    "\n",
    "categorical_columns = ['al_issue_M', 'psp_issue_rgn', 'sex', 'is_client_local', 'has_snils', 'zaim_cards', 'age', \n",
    "                       'responsecode', 'was_garant', 'is_pboul', 'has_foreign_currency_credits', 'cred_line_state',\n",
    "                       'potreb_tot', 'pdl_tot', 'avg_pdl_full_cost']\n",
    "\n",
    "numerical_columns = ['al_amount', 'avg_pdl_amount']\n",
    "\n",
    "wut = ['has_resold_credits', 'avg_payout_period_pdl']\n",
    "\n",
    "megafon = ['al_LIFETIME_BIN', 'al_BLOCK_DUR', 'al_CIRCLE', 'al_ALL_CLC', 'al_PAY_MAX', 'al_SCORE2']\n",
    "\n",
    "outputs = ['res_npl_15']\n",
    "\n",
    "qq = ['court_counts', 'official_count', 'potreb_closed_tot', 'potreb_active_tot', 'potreb_other_states_tot',\n",
    "      'pdl_closed_tot', 'pdl_active_tot', 'pdl_other_states_tot', 'pdl_own_share', 'pdl_delay5_cnt', 'pdl_delay30_cnt',\n",
    "      'pdl_delay60_cnt', 'pdl_delay90_cnt', 'pdl_delay_more_cnt', 'pdl_prolong_cnt',\n",
    "      'pdl_delay5_avg', 'pdl_delay30_avg', 'pdl_delay60_avg', 'pdl_delay90_avg', 'pdl_delay_more_avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decise\n",
    "\n",
    "data_set = data_raw.copy()\n",
    "\n",
    "categorical_columns = categorical_columns + wut\n",
    "numerical_columns = numerical_columns + qq\n",
    "drops = drops + megafon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n",
    "added_categorical = []\n",
    "added_numerical = ['court_rate', 'potreb_closed_rate', 'potreb_active_rate', 'potreb_other_states_rate',\n",
    "                   'pdl_closed_rate', 'pdl_active_rate', \n",
    "                   'pdl_delay5_cnt_rate', 'pdl_delay30_cnt_rate', 'pdl_delay60_cnt_rate', 'pdl_delay90_cnt_rate', 'pdl_delay_more_cnt_rate',\n",
    "                   'pdl_delay5_avg_rate', 'pdl_delay30_avg_rate', 'pdl_delay60_avg_rate', 'pdl_delay90_avg_rate', 'pdl_delay_more_avg_rate',\n",
    "                   'pdl_delay5_cnt_to_avg', 'pdl_delay30_cnt_to_avg', 'pdl_delay60_cnt_to_avg', 'pdl_delay90_cnt_to_avg']\n",
    "\n",
    "added_drop = ['potreb_sum', 'pdl_sum', 'pdl_cnt_sum', 'pdl_avg_sum',\n",
    "              'official_count', 'court_counts', \n",
    "              'potreb_closed_tot', 'potreb_active_tot', 'potreb_other_states_tot',\n",
    "              'pdl_closed_tot', 'pdl_active_tot',\n",
    "              'pdl_delay5_cnt', 'pdl_delay30_cnt', 'pdl_delay60_cnt', 'pdl_delay90_cnt', 'pdl_delay_more_cnt', 'pdl_delay_more_cnt',\n",
    "              'pdl_delay5_avg', 'pdl_delay30_avg', 'pdl_delay60_avg', 'pdl_delay90_avg', 'pdl_delay_more_avg']\n",
    "\n",
    "data_set['court_rate'] = data_set['official_count'] / data_set['court_counts']\n",
    "data_set['potreb_sum'] = data_set['potreb_closed_tot'] + data_set['potreb_active_tot'] + data_set['potreb_other_states_tot']\n",
    "data_set['potreb_closed_rate'] = data_set['potreb_closed_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_active_rate'] = data_set['potreb_active_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_other_states_rate'] = data_set['potreb_other_states_tot'] / data_set['potreb_sum']\n",
    "data_set['pdl_sum'] = data_set['pdl_closed_tot'] + data_set['pdl_active_tot']\n",
    "data_set['pdl_closed_rate'] = data_set['pdl_closed_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_active_rate'] = data_set['pdl_active_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_cnt_sum'] = data_set['pdl_delay5_cnt'] + data_set['pdl_delay30_cnt'] + data_set['pdl_delay60_cnt'] + data_set['pdl_delay90_cnt'] + data_set['pdl_delay_more_cnt'] # + data_set['pdl_prolong_cnt']\n",
    "data_set['pdl_delay5_cnt_rate'] = data_set['pdl_delay5_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay30_cnt_rate'] = data_set['pdl_delay30_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay60_cnt_rate'] = data_set['pdl_delay60_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay90_cnt_rate'] = data_set['pdl_delay90_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay_more_cnt_rate'] = data_set['pdl_delay_more_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_prolong_cnt_rate'] = data_set['pdl_prolong_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_avg_sum'] = data_set['pdl_delay5_avg'] + data_set['pdl_delay30_avg'] + data_set['pdl_delay60_avg'] + data_set['pdl_delay90_avg'] + data_set['pdl_delay_more_avg']\n",
    "data_set['pdl_delay5_avg_rate'] = data_set['pdl_delay5_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay30_avg_rate'] = data_set['pdl_delay30_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay60_avg_rate'] = data_set['pdl_delay60_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay90_avg_rate'] = data_set['pdl_delay90_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay_more_avg_rate'] = data_set['pdl_delay_more_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay5_cnt_to_avg'] = data_set['pdl_delay5_cnt'] / data_set['pdl_delay5_avg']\n",
    "data_set['pdl_delay30_cnt_to_avg'] = data_set['pdl_delay30_cnt'] / data_set['pdl_delay30_avg']\n",
    "data_set['pdl_delay60_cnt_to_avg'] = data_set['pdl_delay60_cnt'] / data_set['pdl_delay60_avg']\n",
    "data_set['pdl_delay90_cnt_to_avg'] = data_set['pdl_delay90_cnt'] / data_set['pdl_delay90_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct added\n",
    "\n",
    "categorical_columns = categorical_columns + added_categorical\n",
    "numerical_columns = numerical_columns + added_numerical\n",
    "drops = drops + added_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n",
    "data_set = data_set.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
    "data_set = data_set.fillna(value=0)\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data_set[category] = data_set[category].astype('category')\n",
    "for numeric in numerical_columns:\n",
    "    data_set[numeric] = data_set[numeric].astype('float64')\n",
    "\n",
    "data_set[outputs[0]] = data_set[outputs[0]].astype('category')\n",
    "data_set = data_set.drop(columns=drops)\n",
    "\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "data = Conductor(data_frame=data_set, target=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoote-func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-params\n",
    "\n",
    "layers = [nn.Linear, nn.Linear]\n",
    "layers_dimensions = [200, 2]\n",
    "activators = [nn.Sigmoid, nn.Sigmoid]\n",
    "preprocessor=None\n",
    "# preprocessor=nn.BatchNorm1d\n",
    "embeddingdrop=0.0\n",
    "# postlayer=nn.Linear\n",
    "postlayer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go model\n",
    "\n",
    "model = Gene(data=data, layers=layers, layers_dimensions=layers_dimensions, activators=activators, preprocessor=preprocessor,\n",
    "             embeddingdrop=embeddingdrop, postlayer=postlayer)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define Optimisation\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "epochs = 300\n",
    "model.fit(optimiser, loss_function, epochs)\n",
    "\n",
    "model.fit_plot()\n",
    "\n",
    "model.summary(loss_function=loss_function, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary(on='train', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='validation', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary(on='test', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat_p = model(data.data.train.categorical, data.data.train.numerical)\n",
    "Y_test_hat_p = model(data.data.test.categorical, data.data.test.numerical)\n",
    "\n",
    "Y_train_hat = numpy.argmax(Y_train_hat_p.detach().numpy(), axis=1)\n",
    "Y_test_hat = numpy.argmax(Y_test_hat_p.detach().numpy(), axis=1)\n",
    "\n",
    "train_roc_auc = roc_auc_score(Y_train, Y_train_hat)\n",
    "test_roc_auc = roc_auc_score(Y_test, Y_test_hat)\n",
    "\n",
    "train_gini = 2 * train_roc_auc - 1\n",
    "test_gini = 2 * test_roc_auc - 1\n",
    "\n",
    "print(\"Train ROC-AUC:\\t {0:.4f}\".format(train_roc_auc))\n",
    "print(\"Test ROC-AUC:\\t {0:.4f}\".format(test_roc_auc))\n",
    "\n",
    "print(\"Train Gini:\\t {0:.4f}\".format(train_gini))\n",
    "print(\"Test Gini:\\t {0:.4f}\".format(test_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 5: added with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who is who\n",
    "\n",
    "drops = ['al_ContractNumber', 'res_npl_90', 'res_payout_principal_inTime', 'res_payout_principal_delay15', \n",
    "         'res_payout_principal_delay30', 'res_payout_principal_delay45', 'res_payout_principal_delay60',\n",
    "         'res_payout_principal_delay90', 'res_payout_tot_inTime', 'res_payout_tot_delay15', 'res_payout_tot_delay30',\n",
    "         'res_payout_tot_delay45', 'res_payout_principal_delay60', 'res_payout_principal_delay90', 'res_payout_tot_inTime',\n",
    "         'res_payout_tot_delay15', 'res_payout_tot_delay30', 'res_payout_tot_delay45', 'res_payout_tot_delay60',\n",
    "         'res_payout_tot_delay90', 'fl_cnt', 'fl_cnt_during_3M', 'fl_cnt_during_12M', 'fl_requests_cnt_12M', 'is_test']\n",
    "\n",
    "categorical_columns = ['al_issue_M', 'psp_issue_rgn', 'sex', 'is_client_local', 'has_snils', 'zaim_cards', 'age', \n",
    "                       'responsecode', 'was_garant', 'is_pboul', 'has_foreign_currency_credits', 'cred_line_state',\n",
    "                       'potreb_tot', 'pdl_tot', 'avg_pdl_full_cost']\n",
    "\n",
    "numerical_columns = ['al_amount', 'avg_pdl_amount']\n",
    "\n",
    "wut = ['has_resold_credits', 'avg_payout_period_pdl']\n",
    "\n",
    "megafon = ['al_LIFETIME_BIN', 'al_BLOCK_DUR', 'al_CIRCLE', 'al_ALL_CLC', 'al_PAY_MAX', 'al_SCORE2']\n",
    "\n",
    "outputs = ['res_npl_15']\n",
    "\n",
    "qq = ['court_counts', 'official_count', 'potreb_closed_tot', 'potreb_active_tot', 'potreb_other_states_tot',\n",
    "      'pdl_closed_tot', 'pdl_active_tot', 'pdl_other_states_tot', 'pdl_own_share', 'pdl_delay5_cnt', 'pdl_delay30_cnt',\n",
    "      'pdl_delay60_cnt', 'pdl_delay90_cnt', 'pdl_delay_more_cnt', 'pdl_prolong_cnt',\n",
    "      'pdl_delay5_avg', 'pdl_delay30_avg', 'pdl_delay60_avg', 'pdl_delay90_avg', 'pdl_delay_more_avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decise\n",
    "\n",
    "data_set = data_raw.copy()\n",
    "\n",
    "categorical_columns = categorical_columns + wut\n",
    "numerical_columns = numerical_columns + qq\n",
    "drops = drops + megafon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n",
    "added_categorical = []\n",
    "added_numerical = ['court_rate', 'potreb_closed_rate', 'potreb_active_rate', 'potreb_other_states_rate',\n",
    "                   'pdl_closed_rate', 'pdl_active_rate', \n",
    "                   'pdl_delay5_cnt_rate', 'pdl_delay30_cnt_rate', 'pdl_delay60_cnt_rate', 'pdl_delay90_cnt_rate', 'pdl_delay_more_cnt_rate',\n",
    "                   'pdl_delay5_avg_rate', 'pdl_delay30_avg_rate', 'pdl_delay60_avg_rate', 'pdl_delay90_avg_rate', 'pdl_delay_more_avg_rate',\n",
    "                   'pdl_delay5_cnt_to_avg', 'pdl_delay30_cnt_to_avg', 'pdl_delay60_cnt_to_avg', 'pdl_delay90_cnt_to_avg']\n",
    "\n",
    "added_drop = ['potreb_sum', 'pdl_sum', 'pdl_cnt_sum', 'pdl_avg_sum',\n",
    "              'official_count', 'court_counts', \n",
    "              'potreb_closed_tot', 'potreb_active_tot', 'potreb_other_states_tot',\n",
    "              'pdl_closed_tot', 'pdl_active_tot',\n",
    "              'pdl_delay5_cnt', 'pdl_delay30_cnt', 'pdl_delay60_cnt', 'pdl_delay90_cnt', 'pdl_delay_more_cnt', 'pdl_delay_more_cnt',\n",
    "              'pdl_delay5_avg', 'pdl_delay30_avg', 'pdl_delay60_avg', 'pdl_delay90_avg', 'pdl_delay_more_avg']\n",
    "\n",
    "data_set['court_rate'] = data_set['official_count'] / data_set['court_counts']\n",
    "data_set['potreb_sum'] = data_set['potreb_closed_tot'] + data_set['potreb_active_tot'] + data_set['potreb_other_states_tot']\n",
    "data_set['potreb_closed_rate'] = data_set['potreb_closed_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_active_rate'] = data_set['potreb_active_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_other_states_rate'] = data_set['potreb_other_states_tot'] / data_set['potreb_sum']\n",
    "data_set['pdl_sum'] = data_set['pdl_closed_tot'] + data_set['pdl_active_tot']\n",
    "data_set['pdl_closed_rate'] = data_set['pdl_closed_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_active_rate'] = data_set['pdl_active_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_cnt_sum'] = data_set['pdl_delay5_cnt'] + data_set['pdl_delay30_cnt'] + data_set['pdl_delay60_cnt'] + data_set['pdl_delay90_cnt'] + data_set['pdl_delay_more_cnt'] # + data_set['pdl_prolong_cnt']\n",
    "data_set['pdl_delay5_cnt_rate'] = data_set['pdl_delay5_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay30_cnt_rate'] = data_set['pdl_delay30_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay60_cnt_rate'] = data_set['pdl_delay60_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay90_cnt_rate'] = data_set['pdl_delay90_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay_more_cnt_rate'] = data_set['pdl_delay_more_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_prolong_cnt_rate'] = data_set['pdl_prolong_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_avg_sum'] = data_set['pdl_delay5_avg'] + data_set['pdl_delay30_avg'] + data_set['pdl_delay60_avg'] + data_set['pdl_delay90_avg'] + data_set['pdl_delay_more_avg']\n",
    "data_set['pdl_delay5_avg_rate'] = data_set['pdl_delay5_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay30_avg_rate'] = data_set['pdl_delay30_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay60_avg_rate'] = data_set['pdl_delay60_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay90_avg_rate'] = data_set['pdl_delay90_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay_more_avg_rate'] = data_set['pdl_delay_more_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay5_cnt_to_avg'] = data_set['pdl_delay5_cnt'] / data_set['pdl_delay5_avg']\n",
    "data_set['pdl_delay30_cnt_to_avg'] = data_set['pdl_delay30_cnt'] / data_set['pdl_delay30_avg']\n",
    "data_set['pdl_delay60_cnt_to_avg'] = data_set['pdl_delay60_cnt'] / data_set['pdl_delay60_avg']\n",
    "data_set['pdl_delay90_cnt_to_avg'] = data_set['pdl_delay90_cnt'] / data_set['pdl_delay90_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct added\n",
    "\n",
    "categorical_columns = categorical_columns + added_categorical\n",
    "numerical_columns = numerical_columns + added_numerical\n",
    "drops = drops + added_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n",
    "data_set = data_set.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
    "data_set = data_set.fillna(value=0)\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data_set[category] = data_set[category].astype('category')\n",
    "for numeric in numerical_columns:\n",
    "    data_set[numeric] = data_set[numeric].astype('float64')\n",
    "\n",
    "data_set[outputs[0]] = data_set[outputs[0]].astype('category')\n",
    "data_set = data_set.drop(columns=drops)\n",
    "\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "data = Conductor(data_frame=data_set, target=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoote-func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-params\n",
    "\n",
    "layers = [nn.Linear, nn.Linear]\n",
    "layers_dimensions = [200, 2]\n",
    "activators = [nn.Sigmoid, nn.Sigmoid]\n",
    "preprocessor=None\n",
    "# preprocessor=nn.BatchNorm1d\n",
    "embeddingdrop=0.0\n",
    "# postlayer=nn.Linear\n",
    "postlayer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go model\n",
    "\n",
    "model = Gene(data=data, layers=layers, layers_dimensions=layers_dimensions, activators=activators, preprocessor=preprocessor,\n",
    "             embeddingdrop=embeddingdrop, postlayer=postlayer)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define Optimisation\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "epochs = 300\n",
    "model.fit(optimiser, loss_function, epochs)\n",
    "\n",
    "model.fit_plot()\n",
    "\n",
    "model.summary(loss_function=loss_function, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary(on='train', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='validation', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary(on='test', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat_p = model(data.data.train.categorical, data.data.train.numerical)\n",
    "Y_test_hat_p = model(data.data.test.categorical, data.data.test.numerical)\n",
    "\n",
    "Y_train_hat = numpy.argmax(Y_train_hat_p.detach().numpy(), axis=1)\n",
    "Y_test_hat = numpy.argmax(Y_test_hat_p.detach().numpy(), axis=1)\n",
    "\n",
    "train_roc_auc = roc_auc_score(Y_train, Y_train_hat)\n",
    "test_roc_auc = roc_auc_score(Y_test, Y_test_hat)\n",
    "\n",
    "train_gini = 2 * train_roc_auc - 1\n",
    "test_gini = 2 * test_roc_auc - 1\n",
    "\n",
    "print(\"Train ROC-AUC:\\t {0:.4f}\".format(train_roc_auc))\n",
    "print(\"Test ROC-AUC:\\t {0:.4f}\".format(test_roc_auc))\n",
    "\n",
    "print(\"Train Gini:\\t {0:.4f}\".format(train_gini))\n",
    "print(\"Test Gini:\\t {0:.4f}\".format(test_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 6: added with replacement + increased N of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# who is who\n",
    "\n",
    "drops = ['al_ContractNumber', 'res_npl_90', 'res_payout_principal_inTime', 'res_payout_principal_delay15', \n",
    "         'res_payout_principal_delay30', 'res_payout_principal_delay45', 'res_payout_principal_delay60',\n",
    "         'res_payout_principal_delay90', 'res_payout_tot_inTime', 'res_payout_tot_delay15', 'res_payout_tot_delay30',\n",
    "         'res_payout_tot_delay45', 'res_payout_principal_delay60', 'res_payout_principal_delay90', 'res_payout_tot_inTime',\n",
    "         'res_payout_tot_delay15', 'res_payout_tot_delay30', 'res_payout_tot_delay45', 'res_payout_tot_delay60',\n",
    "         'res_payout_tot_delay90', 'fl_cnt', 'fl_cnt_during_3M', 'fl_cnt_during_12M', 'fl_requests_cnt_12M', 'is_test']\n",
    "\n",
    "categorical_columns = ['al_issue_M', 'psp_issue_rgn', 'sex', 'is_client_local', 'has_snils', 'zaim_cards', 'age', \n",
    "                       'responsecode', 'was_garant', 'is_pboul', 'has_foreign_currency_credits', 'cred_line_state',\n",
    "                       'potreb_tot', 'pdl_tot', 'avg_pdl_full_cost']\n",
    "\n",
    "numerical_columns = ['al_amount', 'avg_pdl_amount']\n",
    "\n",
    "wut = ['has_resold_credits', 'avg_payout_period_pdl']\n",
    "\n",
    "megafon = ['al_LIFETIME_BIN', 'al_BLOCK_DUR', 'al_CIRCLE', 'al_ALL_CLC', 'al_PAY_MAX', 'al_SCORE2']\n",
    "\n",
    "outputs = ['res_npl_15']\n",
    "\n",
    "qq = ['court_counts', 'official_count', 'potreb_closed_tot', 'potreb_active_tot', 'potreb_other_states_tot',\n",
    "      'pdl_closed_tot', 'pdl_active_tot', 'pdl_other_states_tot', 'pdl_own_share', 'pdl_delay5_cnt', 'pdl_delay30_cnt',\n",
    "      'pdl_delay60_cnt', 'pdl_delay90_cnt', 'pdl_delay_more_cnt', 'pdl_prolong_cnt',\n",
    "      'pdl_delay5_avg', 'pdl_delay30_avg', 'pdl_delay60_avg', 'pdl_delay90_avg', 'pdl_delay_more_avg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# decise\n",
    "\n",
    "data_set = data_raw.copy()\n",
    "\n",
    "categorical_columns = categorical_columns + wut\n",
    "numerical_columns = numerical_columns + qq\n",
    "drops = drops + megafon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features\n",
    "\n",
    "added_categorical = []\n",
    "added_numerical = ['court_rate', 'potreb_closed_rate', 'potreb_active_rate', 'potreb_other_states_rate',\n",
    "                   'pdl_closed_rate', 'pdl_active_rate', \n",
    "                   'pdl_delay5_cnt_rate', 'pdl_delay30_cnt_rate', 'pdl_delay60_cnt_rate', 'pdl_delay90_cnt_rate', 'pdl_delay_more_cnt_rate',\n",
    "                   'pdl_delay5_avg_rate', 'pdl_delay30_avg_rate', 'pdl_delay60_avg_rate', 'pdl_delay90_avg_rate', 'pdl_delay_more_avg_rate',\n",
    "                   'pdl_delay5_cnt_to_avg', 'pdl_delay30_cnt_to_avg', 'pdl_delay60_cnt_to_avg', 'pdl_delay90_cnt_to_avg']\n",
    "\n",
    "added_drop = ['potreb_sum', 'pdl_sum', 'pdl_cnt_sum', 'pdl_avg_sum',\n",
    "              'official_count', 'court_counts', \n",
    "              'potreb_closed_tot', 'potreb_active_tot', 'potreb_other_states_tot',\n",
    "              'pdl_closed_tot', 'pdl_active_tot',\n",
    "              'pdl_delay5_cnt', 'pdl_delay30_cnt', 'pdl_delay60_cnt', 'pdl_delay90_cnt', 'pdl_delay_more_cnt', 'pdl_delay_more_cnt',\n",
    "              'pdl_delay5_avg', 'pdl_delay30_avg', 'pdl_delay60_avg', 'pdl_delay90_avg', 'pdl_delay_more_avg']\n",
    "\n",
    "data_set['court_rate'] = data_set['official_count'] / data_set['court_counts']\n",
    "data_set['potreb_sum'] = data_set['potreb_closed_tot'] + data_set['potreb_active_tot'] + data_set['potreb_other_states_tot']\n",
    "data_set['potreb_closed_rate'] = data_set['potreb_closed_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_active_rate'] = data_set['potreb_active_tot'] / data_set['potreb_sum']\n",
    "data_set['potreb_other_states_rate'] = data_set['potreb_other_states_tot'] / data_set['potreb_sum']\n",
    "data_set['pdl_sum'] = data_set['pdl_closed_tot'] + data_set['pdl_active_tot']\n",
    "data_set['pdl_closed_rate'] = data_set['pdl_closed_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_active_rate'] = data_set['pdl_active_tot'] / data_set['pdl_sum']\n",
    "data_set['pdl_cnt_sum'] = data_set['pdl_delay5_cnt'] + data_set['pdl_delay30_cnt'] + data_set['pdl_delay60_cnt'] + data_set['pdl_delay90_cnt'] + data_set['pdl_delay_more_cnt'] # + data_set['pdl_prolong_cnt']\n",
    "data_set['pdl_delay5_cnt_rate'] = data_set['pdl_delay5_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay30_cnt_rate'] = data_set['pdl_delay30_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay60_cnt_rate'] = data_set['pdl_delay60_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay90_cnt_rate'] = data_set['pdl_delay90_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_delay_more_cnt_rate'] = data_set['pdl_delay_more_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_prolong_cnt_rate'] = data_set['pdl_prolong_cnt'] / data_set['pdl_cnt_sum']\n",
    "data_set['pdl_avg_sum'] = data_set['pdl_delay5_avg'] + data_set['pdl_delay30_avg'] + data_set['pdl_delay60_avg'] + data_set['pdl_delay90_avg'] + data_set['pdl_delay_more_avg']\n",
    "data_set['pdl_delay5_avg_rate'] = data_set['pdl_delay5_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay30_avg_rate'] = data_set['pdl_delay30_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay60_avg_rate'] = data_set['pdl_delay60_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay90_avg_rate'] = data_set['pdl_delay90_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay_more_avg_rate'] = data_set['pdl_delay_more_avg'] / data_set['pdl_avg_sum']\n",
    "data_set['pdl_delay5_cnt_to_avg'] = data_set['pdl_delay5_cnt'] / data_set['pdl_delay5_avg']\n",
    "data_set['pdl_delay30_cnt_to_avg'] = data_set['pdl_delay30_cnt'] / data_set['pdl_delay30_avg']\n",
    "data_set['pdl_delay60_cnt_to_avg'] = data_set['pdl_delay60_cnt'] / data_set['pdl_delay60_avg']\n",
    "data_set['pdl_delay90_cnt_to_avg'] = data_set['pdl_delay90_cnt'] / data_set['pdl_delay90_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct added\n",
    "\n",
    "categorical_columns = categorical_columns + added_categorical\n",
    "numerical_columns = numerical_columns + added_numerical\n",
    "drops = drops + added_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "\n",
    "data_set = data_set.replace([numpy.inf, -numpy.inf], numpy.nan)\n",
    "data_set = data_set.fillna(value=0)\n",
    "\n",
    "for category in categorical_columns:\n",
    "    data_set[category] = data_set[category].astype('category')\n",
    "for numeric in numerical_columns:\n",
    "    data_set[numeric] = data_set[numeric].astype('float64')\n",
    "\n",
    "data_set[outputs[0]] = data_set[outputs[0]].astype('category')\n",
    "data_set = data_set.drop(columns=drops)\n",
    "\n",
    "data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tts\n",
    "\n",
    "data = Conductor(data_frame=data_set, target=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smoote-func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-params\n",
    "\n",
    "layers = [nn.Linear, nn.Linear]\n",
    "layers_dimensions = [200, 2]\n",
    "activators = [nn.Sigmoid, nn.Sigmoid]\n",
    "preprocessor=None\n",
    "# preprocessor=nn.BatchNorm1d\n",
    "embeddingdrop=0.0\n",
    "# postlayer=nn.Linear\n",
    "postlayer=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go model\n",
    "\n",
    "model = Gene(data=data, layers=layers, layers_dimensions=layers_dimensions, activators=activators, preprocessor=preprocessor,\n",
    "             embeddingdrop=embeddingdrop, postlayer=postlayer)\n",
    "\n",
    "print(model)\n",
    "\n",
    "# Define Optimisation\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "epochs = 300\n",
    "model.fit(optimiser, loss_function, epochs)\n",
    "\n",
    "model.fit_plot()\n",
    "\n",
    "model.summary(loss_function=loss_function, show_confusion_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary(on='train', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(on='validation', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.summary(on='test', loss_function=loss_function, show_confusion_matrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_hat_p = model(data.data.train.categorical, data.data.train.numerical)\n",
    "Y_test_hat_p = model(data.data.test.categorical, data.data.test.numerical)\n",
    "\n",
    "Y_train_hat = numpy.argmax(Y_train_hat_p.detach().numpy(), axis=1)\n",
    "Y_test_hat = numpy.argmax(Y_test_hat_p.detach().numpy(), axis=1)\n",
    "\n",
    "train_roc_auc = roc_auc_score(Y_train, Y_train_hat)\n",
    "test_roc_auc = roc_auc_score(Y_test, Y_test_hat)\n",
    "\n",
    "train_gini = 2 * train_roc_auc - 1\n",
    "test_gini = 2 * test_roc_auc - 1\n",
    "\n",
    "print(\"Train ROC-AUC:\\t {0:.4f}\".format(train_roc_auc))\n",
    "print(\"Test ROC-AUC:\\t {0:.4f}\".format(test_roc_auc))\n",
    "\n",
    "print(\"Train Gini:\\t {0:.4f}\".format(train_gini))\n",
    "print(\"Test Gini:\\t {0:.4f}\".format(test_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
